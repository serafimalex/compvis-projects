{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "# Model\n",
    "#model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_batch(model, images):\n",
    "    pred = model(images)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_voc(x_center, y_center, width, height, img_width, img_height):\n",
    "    x_center_abs = x_center * img_width\n",
    "    y_center_abs = y_center * img_height\n",
    "    width_abs = width * img_width\n",
    "    height_abs = height * img_height\n",
    "    \n",
    "    x_min = int(x_center_abs - width_abs / 2)\n",
    "    y_min = int(y_center_abs - height_abs / 2)\n",
    "    x_max = int(x_center_abs + width_abs / 2)\n",
    "    y_max = int(y_center_abs + height_abs / 2)\n",
    "    \n",
    "    return x_min, y_min, x_max, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "def get_intersection_ratio(polygon, bbox):\n",
    "    intersection = polygon.intersection(bbox)\n",
    "    union = polygon.union(bbox)\n",
    "    # Calculate the intersection ratio (area of intersection / area of the original polygon)\n",
    "    iou = intersection.area / union.area\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_spots = [\n",
    "    [(1590,878), (1761, 901), (1756, 1050), (1563, 1036)],\n",
    "[(1467, 757), (1593, 828), (1559, 996), (1410, 896)],\n",
    "[(1353, 684), (1459, 736), (1405, 885), (1287, 807)],\n",
    "[(1243, 639), (1341, 654), (1280, 795), (1183, 732)],\n",
    "[(1153, 588), (1235, 617), (1166, 733), (1084, 677)],\n",
    "[(1107, 537), (1158, 577), (1085, 668), (1020, 616)],\n",
    "[(1016, 493), (1089, 520), (1016, 609), (961, 563)],\n",
    "[(963, 462), (1031, 498), (944, 564), (895, 534)],\n",
    "[(909, 428), (972, 453), (903, 517), (852, 496)],\n",
    "[(878, 401), (920, 416), (849, 485), (803, 437)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_1.jpg\n",
      "\n",
      "0: 352x640 24 cars, 1 truck, 229.9ms\n",
      "Speed: 8.2ms preprocess, 229.9ms inference, 8.3ms postprocess per image at shape (1, 3, 352, 640)\n",
      "01_2.jpg\n",
      "\n",
      "0: 352x640 3 persons, 21 cars, 1 truck, 161.1ms\n",
      "Speed: 8.2ms preprocess, 161.1ms inference, 8.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "01_3.jpg\n",
      "\n",
      "0: 352x640 2 persons, 24 cars, 130.5ms\n",
      "Speed: 0.0ms preprocess, 130.5ms inference, 8.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "02_1.jpg\n",
      "\n",
      "0: 352x640 2 persons, 18 cars, 131.2ms\n",
      "Speed: 0.0ms preprocess, 131.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "02_2.jpg\n",
      "\n",
      "0: 352x640 1 person, 12 cars, 146.6ms\n",
      "Speed: 0.0ms preprocess, 146.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "02_3.jpg\n",
      "\n",
      "0: 352x640 2 persons, 16 cars, 1 truck, 1 traffic light, 132.6ms\n",
      "Speed: 9.1ms preprocess, 132.6ms inference, 8.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "03_1.jpg\n",
      "\n",
      "0: 352x640 1 person, 25 cars, 1 traffic light, 130.4ms\n",
      "Speed: 8.2ms preprocess, 130.4ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "03_2.jpg\n",
      "\n",
      "0: 352x640 2 persons, 23 cars, 141.3ms\n",
      "Speed: 8.2ms preprocess, 141.3ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "03_3.jpg\n",
      "\n",
      "0: 352x640 4 persons, 20 cars, 130.1ms\n",
      "Speed: 0.0ms preprocess, 130.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "04_1.jpg\n",
      "\n",
      "0: 352x640 20 cars, 2 trucks, 138.4ms\n",
      "Speed: 0.0ms preprocess, 138.4ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "04_2.jpg\n",
      "\n",
      "0: 352x640 1 person, 21 cars, 129.9ms\n",
      "Speed: 8.2ms preprocess, 129.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "04_3.jpg\n",
      "\n",
      "0: 352x640 2 persons, 21 cars, 130.6ms\n",
      "Speed: 8.2ms preprocess, 130.6ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "05_1.jpg\n",
      "\n",
      "0: 352x640 7 cars, 1 bus, 4 trucks, 1 traffic light, 122.0ms\n",
      "Speed: 8.0ms preprocess, 122.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "05_2.jpg\n",
      "\n",
      "0: 352x640 3 persons, 8 cars, 3 trucks, 138.1ms\n",
      "Speed: 0.0ms preprocess, 138.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "05_3.jpg\n",
      "\n",
      "0: 352x640 1 person, 9 cars, 2 trucks, 132.4ms\n",
      "Speed: 0.0ms preprocess, 132.4ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "06_1.jpg\n",
      "\n",
      "0: 352x640 4 cars, 123.1ms\n",
      "Speed: 0.0ms preprocess, 123.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "06_2.jpg\n",
      "\n",
      "0: 352x640 3 cars, 130.1ms\n",
      "Speed: 8.2ms preprocess, 130.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "06_3.jpg\n",
      "\n",
      "0: 352x640 3 cars, 121.9ms\n",
      "Speed: 0.0ms preprocess, 121.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "07_1.jpg\n",
      "\n",
      "0: 352x640 19 cars, 1 truck, 123.6ms\n",
      "Speed: 8.0ms preprocess, 123.6ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "07_2.jpg\n",
      "\n",
      "0: 352x640 19 cars, 1 truck, 137.9ms\n",
      "Speed: 0.0ms preprocess, 137.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "07_3.jpg\n",
      "\n",
      "0: 352x640 1 person, 20 cars, 1 truck, 122.9ms\n",
      "Speed: 0.0ms preprocess, 122.9ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "08_1.jpg\n",
      "\n",
      "0: 352x640 2 persons, 17 cars, 153.9ms\n",
      "Speed: 0.0ms preprocess, 153.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "08_2.jpg\n",
      "\n",
      "0: 352x640 3 persons, 17 cars, 1 truck, 145.9ms\n",
      "Speed: 0.0ms preprocess, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "08_3.jpg\n",
      "\n",
      "0: 352x640 2 persons, 13 cars, 124.2ms\n",
      "Speed: 0.0ms preprocess, 124.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "09_1.jpg\n",
      "\n",
      "0: 352x640 18 cars, 3 trucks, 146.3ms\n",
      "Speed: 8.2ms preprocess, 146.3ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "09_2.jpg\n",
      "\n",
      "0: 352x640 1 person, 17 cars, 1 truck, 115.3ms\n",
      "Speed: 0.0ms preprocess, 115.3ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "09_3.jpg\n",
      "\n",
      "0: 352x640 14 cars, 1 truck, 139.3ms\n",
      "Speed: 8.3ms preprocess, 139.3ms inference, 8.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "10_1.jpg\n",
      "\n",
      "0: 352x640 19 cars, 1 truck, 130.8ms\n",
      "Speed: 0.0ms preprocess, 130.8ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "10_2.jpg\n",
      "\n",
      "0: 352x640 16 cars, 1 truck, 138.7ms\n",
      "Speed: 0.0ms preprocess, 138.7ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "10_3.jpg\n",
      "\n",
      "0: 352x640 2 persons, 15 cars, 1 truck, 171.8ms\n",
      "Speed: 8.2ms preprocess, 171.8ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "11_1.jpg\n",
      "\n",
      "0: 352x640 2 persons, 20 cars, 2 trucks, 1 traffic light, 138.3ms\n",
      "Speed: 8.2ms preprocess, 138.3ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "11_2.jpg\n",
      "\n",
      "0: 352x640 1 person, 19 cars, 4 trucks, 1 traffic light, 131.0ms\n",
      "Speed: 0.0ms preprocess, 131.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "11_3.jpg\n",
      "\n",
      "0: 352x640 1 person, 17 cars, 1 truck, 1 traffic light, 132.0ms\n",
      "Speed: 0.0ms preprocess, 132.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "11_4.jpg\n",
      "\n",
      "0: 352x640 1 person, 16 cars, 1 truck, 1 traffic light, 118.4ms\n",
      "Speed: 8.1ms preprocess, 118.4ms inference, 8.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "12_1.jpg\n",
      "\n",
      "0: 352x640 2 persons, 18 cars, 1 truck, 122.1ms\n",
      "Speed: 0.0ms preprocess, 122.1ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "12_2.jpg\n",
      "\n",
      "0: 352x640 2 persons, 13 cars, 3 trucks, 139.0ms\n",
      "Speed: 0.0ms preprocess, 139.0ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "12_3.jpg\n",
      "\n",
      "0: 352x640 2 persons, 17 cars, 2 trucks, 132.2ms\n",
      "Speed: 8.2ms preprocess, 132.2ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "12_4.jpg\n",
      "\n",
      "0: 352x640 17 cars, 1 bus, 2 trucks, 137.8ms\n",
      "Speed: 0.0ms preprocess, 137.8ms inference, 8.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "13_1.jpg\n",
      "\n",
      "0: 352x640 10 cars, 2 trucks, 1 traffic light, 147.5ms\n",
      "Speed: 0.0ms preprocess, 147.5ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "13_2.jpg\n",
      "\n",
      "0: 352x640 1 person, 9 cars, 1 truck, 1 traffic light, 153.7ms\n",
      "Speed: 0.0ms preprocess, 153.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "13_3.jpg\n",
      "\n",
      "0: 352x640 2 persons, 10 cars, 1 truck, 1 traffic light, 132.8ms\n",
      "Speed: 8.2ms preprocess, 132.8ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "13_4.jpg\n",
      "\n",
      "0: 352x640 3 persons, 15 cars, 1 truck, 1 traffic light, 188.1ms\n",
      "Speed: 0.0ms preprocess, 188.1ms inference, 8.2ms postprocess per image at shape (1, 3, 352, 640)\n",
      "14_1.jpg\n",
      "\n",
      "0: 352x640 1 person, 4 cars, 1 truck, 1 traffic light, 169.7ms\n",
      "Speed: 0.0ms preprocess, 169.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "14_2.jpg\n",
      "\n",
      "0: 352x640 1 person, 7 cars, 1 truck, 238.3ms\n",
      "Speed: 8.0ms preprocess, 238.3ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "14_3.jpg\n",
      "\n",
      "0: 352x640 1 person, 4 cars, 1 truck, 164.7ms\n",
      "Speed: 0.0ms preprocess, 164.7ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "14_4.jpg\n",
      "\n",
      "0: 352x640 2 persons, 5 cars, 142.1ms\n",
      "Speed: 8.0ms preprocess, 142.1ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "15_1.jpg\n",
      "\n",
      "0: 352x640 2 persons, 11 cars, 147.8ms\n",
      "Speed: 8.0ms preprocess, 147.8ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "15_2.jpg\n",
      "\n",
      "0: 352x640 1 person, 11 cars, 1 truck, 130.4ms\n",
      "Speed: 0.0ms preprocess, 130.4ms inference, 0.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "15_3.jpg\n",
      "\n",
      "0: 352x640 10 cars, 1 truck, 140.8ms\n",
      "Speed: 8.0ms preprocess, 140.8ms inference, 8.0ms postprocess per image at shape (1, 3, 352, 640)\n",
      "15_4.jpg\n",
      "\n",
      "0: 352x640 1 person, 8 cars, 122.6ms\n",
      "Speed: 0.0ms preprocess, 122.6ms inference, 8.2ms postprocess per image at shape (1, 3, 352, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pybboxes\n",
    "\n",
    "def iterate_folder(path, results_path):\n",
    "    images = os.listdir(path)\n",
    "    for image in images:\n",
    "        if image[-4:] == '.jpg':\n",
    "            print(image)\n",
    "            img_path = os.path.join(path, image)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            pred = get_prediction_batch(model, img)\n",
    "            \n",
    "            labels, cord_thres = pred[0].boxes.data[:, -1].numpy().astype(int), pred[0].boxes.data[:, :-1].numpy()\n",
    "\n",
    "            np.random.seed(42)  # For reproducibility\n",
    "            iou_ratios = []\n",
    "            colors = np.random.randint(0, 255, size=(len(pred), 3), dtype='uint8')\n",
    "            for j in range(len(parking_spots)):\n",
    "                spot = parking_spots[j]\n",
    "                polygon = Polygon(spot)\n",
    "                for i, (coords, label) in enumerate(zip(cord_thres, labels)):\n",
    "                    if label == 2:\n",
    "                        conf = coords[4]\n",
    "                        coords = coords.astype(int)\n",
    "                        x1, y1, x2, y2 = coords[0], coords[1], coords[2], coords[3] #yolo_to_voc(coords[0], coords[1], coords[2], coords[3], img.shape[1], img.shape[0])\n",
    "                        \n",
    "                        voc_bbox = (x1, y1, x2, y2)\n",
    "                        bbox_points = [(voc_bbox[0], voc_bbox[1]), (voc_bbox[0], voc_bbox[3]), (voc_bbox[2], voc_bbox[3]), (voc_bbox[2], voc_bbox[1])]\n",
    "                        bbox = Polygon(bbox_points)\n",
    "                        ratio = get_intersection_ratio(polygon, bbox)\n",
    "                        pts = np.array([spot],\n",
    "                                    np.int32)\n",
    "                        pts = pts.reshape((-1, 1, 2))\n",
    "\n",
    "                        if ratio > 0.3:\n",
    "                            iou_ratios.append((ratio, j, i))\n",
    "\n",
    "            sorted_list = sorted(iou_ratios, key=lambda x: x[0])\n",
    "            parking_occupied = [0 for i in range(0, 10)]\n",
    "            car_used = [0 for i in range(len(cord_thres))]\n",
    "            for tpl in sorted_list:\n",
    "                if parking_occupied[tpl[1]] == 0 and car_used[tpl[2]] == 0:\n",
    "                    parking_occupied[tpl[1]] = 1\n",
    "                    car_used[tpl[2]] = 1\n",
    "            txt_path = os.path.join(path, image[:-4] + '_query.txt')\n",
    "            file1 = open(txt_path, 'r')\n",
    "            Lines = file1.readlines()\n",
    "            query = []\n",
    "            all_true = True\n",
    "            results = []\n",
    "            for line in Lines[1:]:\n",
    "                line = line.strip().split(\" \")\n",
    "                results.append( (int(line[0]), parking_occupied[int(line[0])-1]) )\n",
    "            file_path = image[:-4] + \"_predicted.txt\"\n",
    "            with open(os.path.join(results_path, file_path), 'a') as file:\n",
    "                file.write(str(len(results)) + '\\n')\n",
    "                for line in results:\n",
    "                    to_write = str(line[0]) + \" \" + str(line[1]) \n",
    "                    file.write(to_write + '\\n')\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "test_path = \"./test/Task1\"\n",
    "\n",
    "results_path = \"./submission_files/407_Serafim_Alex/Task1\"\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "iterate_folder(test_path, results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
